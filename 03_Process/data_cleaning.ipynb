{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime, date\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `glob` to iterate through all 12 csv files (one for each month) \n",
    "and create a list of dataframes. We concatenate these dataframes \n",
    "together to create a single dataframe `df` for the past year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = os.path.abspath(\"\")\n",
    "csv_folder = \"/\".join(dir.split(\"\\\\\")[:-1] + [\"02_Prepare\", \"CSVs\", \"*\"])\n",
    "\n",
    "csv_list = []\n",
    "for csv in glob.glob(csv_folder):\n",
    "    csv_list.append(pd.read_csv(csv, index_col=None, header=0))\n",
    "\n",
    "df = pd.concat(csv_list, axis=0, ignore_index=True)\n",
    "\n",
    "del dir, csv_folder, csv_list, csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the `shape` and `dtypes` attributes of the dataframe for meta \n",
    "information of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We change `\"started_at\"` and `\"ended_at\"` columns to be datetimes \n",
    "instead of strings. We then create a `\"ride_length\"` column which is the\n",
    "time length of the ride in minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: datetime.strptime(x, \"%Y-%m-%d %H:%M:%S\")\n",
    "df[\"started_at\"] = df[\"started_at\"].apply(f)\n",
    "df[\"ended_at\"] = df[\"ended_at\"].apply(f)\n",
    "\n",
    "df[\"ride_length\"] = df[\"ended_at\"] - df[\"started_at\"]\n",
    "df[\"ride_length\"] = df[\"ride_length\"].apply(lambda x: x.total_seconds() / 60)\n",
    "\n",
    "\n",
    "del f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating `\"season\"`, `\"month\"`, `\"day_of_week\"`, and `\"start_hour\"` \n",
    "columns based on the `\"started_at\"` column. Althought most of these may \n",
    "not be necessary to create, having them will speed up some analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Season Column ---------------------------------------------------------------\n",
    "Y = 2000  # Dummy leap year to allow input X-02-29 (leap day)\n",
    "seasons = [('winter', (date(Y,  1,  1),  date(Y,  3, 20))),\n",
    "           ('spring', (date(Y,  3, 21),  date(Y,  6, 20))),\n",
    "           ('summer', (date(Y,  6, 21),  date(Y,  9, 22))),\n",
    "           ('autumn', (date(Y,  9, 23),  date(Y, 12, 20))),\n",
    "           ('winter', (date(Y, 12, 21),  date(Y, 12, 31)))]\n",
    "\n",
    "def get_season(now):\n",
    "    \"\"\"Return current nothern hemisphere season\"\"\"\n",
    "    if isinstance(now, datetime):\n",
    "        now = now.date()\n",
    "    now = now.replace(year=Y)\n",
    "    return next(season for season, (start, end) in seasons\n",
    "                if start <= now <= end)\n",
    "\n",
    "df[\"season\"] = df[\"started_at\"].apply(lambda x: get_season(x))\n",
    "\n",
    "\n",
    "# Other columns ---------------------------------------------------------------\n",
    "df[\"month\"] = df[\"started_at\"].apply(lambda x: datetime.strftime(x, \"%m\"))\n",
    "df['day_of_week'] = df['started_at'].apply(lambda x: x.weekday())\n",
    "df[\"start_hour\"] = df[\"started_at\"].apply(lambda x: datetime.strftime(x, \"%H:00\"))\n",
    "\n",
    "\n",
    "del Y, seasons, get_season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check to see which columns contain null/NaN/na values and how many."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ride_id: 0\n",
      "rideable_type: 0\n",
      "started_at: 0\n",
      "ended_at: 0\n",
      "start_station_name: 790207\n",
      "start_station_id: 790204\n",
      "end_station_name: 843361\n",
      "end_station_id: 843361\n",
      "start_lat: 0\n",
      "start_lng: 0\n",
      "end_lat: 4766\n",
      "end_lng: 4766\n",
      "member_casual: 0\n",
      "ride_length: 0\n",
      "day_of_week: 0\n",
      "start_hour: 0\n",
      "season: 0\n",
      "month: 0\n"
     ]
    }
   ],
   "source": [
    "null = df[df.isnull().any(axis=1)]\n",
    "for column in null.columns:\n",
    "    print(f\"{column}: {null[column].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "was found that every end_lat that had NaN also had NaN for end_station_name and end_station_id, so no way to recover that data. this only made up ~4800 rows out of 5.75 million so i dropped them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[(df[\"end_station_name\"].isna()) & (df[\"end_lat\"].isna())].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>ride_length</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>season</th>\n",
       "      <th>month</th>\n",
       "      <th>start_coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C809ED75D6160B2A</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-05-30 11:58:15</td>\n",
       "      <td>2021-05-30 12:10:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.90</td>\n",
       "      <td>-87.63</td>\n",
       "      <td>41.89</td>\n",
       "      <td>-87.61</td>\n",
       "      <td>casual</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>6</td>\n",
       "      <td>11:00</td>\n",
       "      <td>spring</td>\n",
       "      <td>05</td>\n",
       "      <td>(41.9, -87.63)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DD59FDCE0ACACAF3</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-05-30 11:29:14</td>\n",
       "      <td>2021-05-30 12:14:09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.88</td>\n",
       "      <td>-87.62</td>\n",
       "      <td>41.79</td>\n",
       "      <td>-87.58</td>\n",
       "      <td>casual</td>\n",
       "      <td>44.916667</td>\n",
       "      <td>6</td>\n",
       "      <td>11:00</td>\n",
       "      <td>spring</td>\n",
       "      <td>05</td>\n",
       "      <td>(41.88, -87.62)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0AB83CB88C43EFC2</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-05-30 14:24:01</td>\n",
       "      <td>2021-05-30 14:25:13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.92</td>\n",
       "      <td>-87.70</td>\n",
       "      <td>41.92</td>\n",
       "      <td>-87.70</td>\n",
       "      <td>casual</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>6</td>\n",
       "      <td>14:00</td>\n",
       "      <td>spring</td>\n",
       "      <td>05</td>\n",
       "      <td>(41.92, -87.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7881AC6D39110C60</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-05-30 14:25:51</td>\n",
       "      <td>2021-05-30 14:41:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.92</td>\n",
       "      <td>-87.70</td>\n",
       "      <td>41.94</td>\n",
       "      <td>-87.69</td>\n",
       "      <td>casual</td>\n",
       "      <td>15.216667</td>\n",
       "      <td>6</td>\n",
       "      <td>14:00</td>\n",
       "      <td>spring</td>\n",
       "      <td>05</td>\n",
       "      <td>(41.92, -87.7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>853FA701B4582BAF</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2021-05-30 18:15:39</td>\n",
       "      <td>2021-05-30 18:22:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.94</td>\n",
       "      <td>-87.69</td>\n",
       "      <td>41.94</td>\n",
       "      <td>-87.70</td>\n",
       "      <td>casual</td>\n",
       "      <td>6.883333</td>\n",
       "      <td>6</td>\n",
       "      <td>18:00</td>\n",
       "      <td>spring</td>\n",
       "      <td>05</td>\n",
       "      <td>(41.94, -87.69)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type          started_at            ended_at  \\\n",
       "0  C809ED75D6160B2A  electric_bike 2021-05-30 11:58:15 2021-05-30 12:10:39   \n",
       "1  DD59FDCE0ACACAF3  electric_bike 2021-05-30 11:29:14 2021-05-30 12:14:09   \n",
       "2  0AB83CB88C43EFC2  electric_bike 2021-05-30 14:24:01 2021-05-30 14:25:13   \n",
       "3  7881AC6D39110C60  electric_bike 2021-05-30 14:25:51 2021-05-30 14:41:04   \n",
       "4  853FA701B4582BAF  electric_bike 2021-05-30 18:15:39 2021-05-30 18:22:32   \n",
       "\n",
       "  start_station_name start_station_id end_station_name end_station_id  \\\n",
       "0                NaN              NaN              NaN            NaN   \n",
       "1                NaN              NaN              NaN            NaN   \n",
       "2                NaN              NaN              NaN            NaN   \n",
       "3                NaN              NaN              NaN            NaN   \n",
       "4                NaN              NaN              NaN            NaN   \n",
       "\n",
       "   start_lat  start_lng  end_lat  end_lng member_casual  ride_length  \\\n",
       "0      41.90     -87.63    41.89   -87.61        casual    12.400000   \n",
       "1      41.88     -87.62    41.79   -87.58        casual    44.916667   \n",
       "2      41.92     -87.70    41.92   -87.70        casual     1.200000   \n",
       "3      41.92     -87.70    41.94   -87.69        casual    15.216667   \n",
       "4      41.94     -87.69    41.94   -87.70        casual     6.883333   \n",
       "\n",
       "   day_of_week start_hour  season month     start_coords  \n",
       "0            6      11:00  spring    05   (41.9, -87.63)  \n",
       "1            6      11:00  spring    05  (41.88, -87.62)  \n",
       "2            6      14:00  spring    05   (41.92, -87.7)  \n",
       "3            6      14:00  spring    05   (41.92, -87.7)  \n",
       "4            6      18:00  spring    05  (41.94, -87.69)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"start_coords\"] = list(zip(df.start_lat, df.start_lng))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_coords_count = df.groupby(\"start_station_name\").start_coords.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dict with station names as keys and (lat, long) coords as values. also create a dict with coords as keys and station names as values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = df.start_station_name.value_counts().index.tolist()\n",
    "stations_coords = {}\n",
    "\n",
    "for station in stations:\n",
    "    t = df.loc[df.start_station_name == station]\n",
    "    stations_coords[station] = (\n",
    "        t.iloc[0, 8],\n",
    "        t.iloc[0, 9]\n",
    "    )\n",
    "\n",
    "reverse_coords = {values: keys for keys, values in stations_coords.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creates start_coords column and end_coords column.  \n",
    "uses defined functions to choose the closest station coords based on dicts for rows with NaN for station name(s).  \n",
    "drops redundant columns, makes all lats and longs for the same for each station observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_between_points(x, point):\n",
    "    \"\"\"Returns distance between x and point using pythag\"\"\"\n",
    "    return np.sqrt((point[0]-x[0])**2 + (point[1]-x[1])**2)\n",
    "\n",
    "def minimize(x, point_l):\n",
    "    \"\"\"Returns point from point_l (point list) that x is closest to\"\"\"\n",
    "    lst = np.array([d_between_points(x, i) for i in point_l])\n",
    "    idx = lst.argmin()\n",
    "\n",
    "    return point_l[idx]\n",
    "\n",
    "\n",
    "df[\"start_coords\"] = list(zip(df[\"start_lat\"], df[\"start_lng\"]))\n",
    "df[\"end_coords\"] = list(zip(df[\"end_lat\"], df[\"end_lng\"]))\n",
    "\n",
    "possible_coords = list(reverse_coords.keys())\n",
    "\n",
    "df.loc[df[\"start_station_name\"].isna(), \"start_station_name\"] = df.loc[df[\"start_station_name\"].isna(), \"start_coords\"].apply(lambda x: reverse_coords[minimize(x, point_l=possible_coords)])\n",
    "df.loc[df[\"end_station_name\"].isna(), \"end_station_name\"] = df.loc[df[\"end_station_name\"].isna(), \"end_coords\"].apply(lambda x: reverse_coords[minimize(x, point_l=possible_coords)])\n",
    "\n",
    "df.drop([\"start_station_id\", \"end_station_id\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "df[\"start_coords\"] = df[\"start_station_name\"].apply(lambda x: stations_coords[x])\n",
    "df[\"end_coords\"] = df[\"end_station_name\"].apply(lambda x: stations_coords[x])\n",
    "\n",
    "df[\"start_lat\"] = df[\"start_coords\"].apply(lambda x: x[0])\n",
    "df[\"start_lng\"] = df[\"start_coords\"].apply(lambda x: x[1])\n",
    "df[\"end_lat\"] = df[\"end_coords\"].apply(lambda x: x[0])\n",
    "df[\"end_lng\"] = df[\"end_coords\"].apply(lambda x: x[1])\n",
    "\n",
    "\n",
    "df.drop([\"start_coords\", \"end_coords\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "swaps started_at and ended_at for observations with negative ride length (only 140 so i prob could've just ignored but either way it won't make much of a difference.)  \n",
    "recomputes ride_length as opposed to just multiplying by -1 bc I felt like it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = df[\"ride_length\"] < 0\n",
    "df.loc[idx, [\"started_at\", \"ended_at\"]] = df.loc[idx, [\"ended_at\", \"started_at\"]].values\n",
    "\n",
    "df['ride_length'] = df['ended_at'] - df['started_at']\n",
    "df['ride_length'] = df['ride_length'].apply(lambda x: x.total_seconds() / 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saves dataframe to csv for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Clean_Cyclistic_Data.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d45edfa029243f1b8ef4e844982c6953fc65f9dbbb981b30f79653022d49b3e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
